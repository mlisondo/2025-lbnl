{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec3808b",
   "metadata": {},
   "source": [
    "# Transformers Tutorial: Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e67d90-1a4a-4d2c-9a7a-9897fd71cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /global/common/software/nersc9/pytorch/2.6.0/lib/python3.12/site-packages/torchvision-0.21.0+7af6987-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /global/common/software/nersc9/pytorch/2.6.0/lib/python3.12/site-packages/setuptools-75.8.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /global/common/software/nersc9/pytorch/2.6.0/lib/python3.12/site-packages/pillow-11.1.0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: einops in /global/homes/m/mlisondo/.local/perlmutter/pytorch2.6.0/lib/python3.12/site-packages (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2285437c-72ac-42c7-a70e-655b8339ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from network import PET2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33ea9e-e41d-4dc8-ae2e-340089f9924e",
   "metadata": {},
   "source": [
    "### Let's open the training and validation files containing examples for top quarks (signal) and QCD jets (background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bbb048-dc2f-4f03-9f02-f3f4e53fb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/global/cfs/cdirs/trn016/transformer'\n",
    "train_data = load_data('top',input_folder,batch=256,dataset_type='train',num_evt = 100_000)\n",
    "val_data = load_data('top',input_folder,batch=256,dataset_type='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aeec21c-cfe9-47e3-9250-e14724fddce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 390 batches of events for training and 1574 for validation\n"
     ]
    }
   ],
   "source": [
    "print (f\"Loading {len(train_data)} batches of events for training and {len(val_data)} for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38a93c-14f3-49ec-90c7-65baeb1a10c8",
   "metadata": {},
   "source": [
    "### Let's now load the PET Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e40917-b98d-4423-a5fc-1622d8db05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_dim':4,\n",
    "    'hidden_size': 128,\n",
    "    'num_transformers': 8, #number of transformer blocks used\n",
    "    'num_transformers_head':2, #number of transformer blocks used in the task-specific block\n",
    "    'num_heads':8, #number of heads for multi-head attention\n",
    "    'K':10, #number of neighbors considered for the kNN\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a778d5c8-5f18-401b-b944-38422d1164ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PET2(**config) #remember the inputs are delta eta, delta phi, log(pT), log(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f95bf4-8f95-4742-aa4b-dc6f3e211511",
   "metadata": {},
   "source": [
    "### Now we are going to create the training class that will train the model, but first, let's set up the learning rate and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73397f76-9973-4bad-9bf7-146a01408397",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 5e-4\n",
    "epochs = 10\n",
    "patience = 10 # Number of consecutive epochs to stop the training if the validation loss does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e6c7534-3b5f-4d2d-b53c-3f17389a9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = utils.Trainer(train_data,val_data,model,lr,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea3830-5f46-45eb-b27c-0478c17451de",
   "metadata": {},
   "source": [
    "### Let's train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb53f3c-c01d-4d0c-a16f-28fb5704a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss=0.2764, validation loss=0.2403\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc16252-f4ae-4027-88ef-23b258ee0ffd",
   "metadata": {},
   "source": [
    "### Now let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256fe45c-70dc-46b6-a9db-1a8661a8bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data('top',input_folder,batch=128,dataset_type='test')\n",
    "predictions, labels = trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6737db7-d095-4762-a2fd-2b38aec08642",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_metrics(predictions,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4565450-45ce-4b2e-b5ec-0fb605a44fc3",
   "metadata": {},
   "source": [
    "### Now let's load the pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23758746-b7a2-4ee0-97e0-1c27fb471ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.restore_checkpoint(model,input_folder,'best_model_pretrain_s.pt')\n",
    "#These messages are all fine and related to model layers that are not relevant for classiciation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef8519-4b95-486a-9bbd-ec1baafcda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 5e-5 #Notice the learning rate is much smaller than before\n",
    "epochs = 10\n",
    "patience = 10 # Number of consecutive epochs to stop the training if the validation loss does not improve\n",
    "trainer = utils.Trainer(train_data,val_data,model,lr,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe0bae-7429-4398-ace5-db793e47c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae92964-a2fe-4805-a113-d9948c9cf2f2",
   "metadata": {},
   "source": [
    "### Because the pre-trained model already starts from useful weights, they are quicker to overtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f5ed7-2f4b-478f-be48-ac20e8cb375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels = trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c509579-16cb-4d7d-ab3b-aacaccc69082",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_metrics(predictions,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c1c41-0f8f-4fdf-897f-81f4ed0da18d",
   "metadata": {},
   "source": [
    "### Try changing the hyperparameters of the model to see if you can improve the results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.6.0",
   "language": "python",
   "name": "pytorch-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
